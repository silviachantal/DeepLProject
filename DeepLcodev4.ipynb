{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3ZT4LulHJ7C"
      },
      "source": [
        "First I import the packages I need\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y6JZlyDkHW2J"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tN4QNifzEa_C"
      },
      "outputs": [],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PCUeGSn5EfVj"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.model_selection import train_test_split # we'll use it to split the training set into training and validation data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1t3eDtQUUuG"
      },
      "source": [
        "Here I define my dependent variables (the predictions of valence & arousal) so Y (https://machinelearningmastery.com/multi-label-classification-with-deep-learning/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9AZtgjUVEzDN"
      },
      "outputs": [],
      "source": [
        "def load_dataframe(filename):\n",
        "  dataframe = pd.read_json(filename)\n",
        "  dataframe = dataframe.T\n",
        "  #print(dataframe.head)\n",
        "  return dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hfDK7gelUGsa"
      },
      "outputs": [],
      "source": [
        "def loadgroundtruth(dataframe):\n",
        "  #I first zip values of valence and arousal together \n",
        "  Y = list(zip(dataframe[\"valence\"], dataframe[\"activation\"]))\n",
        "  Y = [ torch.tensor(datapoint, device=device, dtype=torch.float) for datapoint in Y]\n",
        "  return Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ED6FJHmFHop"
      },
      "outputs": [],
      "source": [
        "def load_features(dataframe):\n",
        "  X = dataframe[\"features\"]\n",
        "  X = [torch.tensor(datapoint, device=device, dtype=torch.float) for datapoint in X]\n",
        "  return X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RilxxMKkZxBR"
      },
      "outputs": [],
      "source": [
        "train_df = load_dataframe('/content/drive/MyDrive/DeepLProject/train.json')\n",
        "dev_df = load_dataframe('/content/drive/MyDrive/DeepLProject/test.json')\n",
        "\n",
        "train_X = load_features(train_df)\n",
        "train_Y = loadgroundtruth(train_df)\n",
        "dev_X = load_features(dev_df)\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(train_X, train_Y, test_size=0.1, random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#print(X[0]) #list of tensors\n",
        "#print(X[0].shape)"
      ],
      "metadata": {
        "id": "m0bo_qHoaSbU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTuNH5rha9Kn",
        "outputId": "d08cbb7b-cc36-436f-f6f5-7a6bfa2887ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.4315, 0.7099], device='cuda:0')\n",
            "(tensor([[0., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [1., 1.]], device='cuda:0'), tensor([1240, 3194, 1023, 2343], device='cuda:0'))\n"
          ]
        }
      ],
      "source": [
        "def analyze(Y):\n",
        "  c = Y.sum(dim=0) / len(Y)\n",
        "  print(c)\n",
        "  print(torch.unique(Y, dim=0 , return_counts=True))\n",
        "analyze(torch.stack(train_Y, dim=0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjqGAvptO61s"
      },
      "source": [
        "the lstm will only accept one entry of our sequence at a time\n",
        "so we need to iterate voer the first dimension of the data matrix, \n",
        "and pass this to the lstm while updating the, new freshly generated hidden and cell states\n",
        "one application of the lstm gives somthing like, (out, (h1,c1)) = self.lstm(x[0], (h0, c0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDFSJ2o_ZJ0d"
      },
      "source": [
        "sequence_length, n_features = x.shape # the shape gives us the size of each dimension of the matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9t78weXolw98"
      },
      "source": [
        "The schedule your learning rate is going to follow is a major hyperparameter that you want to tune. PyTorch provides support for scheduling learning rates with itâ€™s torch.optim.lr_scheduler module which has a variety of learning rate schedules. The following example demonstrates one such example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MiyoAk2iznOa"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import itertools\n",
        "def evaluate(model, X, Y):\n",
        "    thresholds = [0.25, 0.5, 0.75]\n",
        "    num_correct = np.zeros((len(thresholds),len(thresholds)), dtype=int)\n",
        "\n",
        "    num_samples = len(X)\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for x,y in zip(X,Y):        \n",
        "            scores = model(x)\n",
        "            ground_truth = y >= 0.5 # [False, True]\n",
        "            for row, column in itertools.product(range(len(thresholds)), range(len(thresholds))):\n",
        "              c0_th = thresholds[row]\n",
        "              c1_th = thresholds[column]\n",
        "              predictions = torch.zeros(scores.shape, dtype=torch.bool, device=device)\n",
        "              predictions[0] = scores[0] >= c0_th\n",
        "              predictions[1] = scores[1] >= c1_th\n",
        "              if torch.equal(predictions, ground_truth):\n",
        "                num_correct[row, column] += 1\n",
        "\n",
        "    accuracy = num_correct / num_samples\n",
        "    accuracy = np.round(accuracy * 100 , 4)\n",
        "    print(accuracy)\n",
        "\n",
        "    maximum = np.argmax(accuracy)\n",
        "    c0_th = thresholds[int(maximum // len(thresholds))]\n",
        "    c1_th = thresholds[maximum % len(thresholds)]\n",
        "    maximum = accuracy.max()\n",
        "\n",
        "    model.train()\n",
        "    return maximum, (c0_th, c1_th)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ctoaMVDYpkhs"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "def train_step(model, optimizer, X_train, Y_train, batch_size=32):\n",
        "  criterion= nn.MSELoss()\n",
        "  \n",
        "  e = 1e-7 \n",
        "\n",
        "  def criterion(props, y):\n",
        "    return (- y * torch.log(props + e) - (1 -y)*torch.log(1 - props + e)).sum()\n",
        "    \n",
        "\n",
        "  losses=[]\n",
        "  for _ in range(batch_size):\n",
        "    index = random.randint(0,len(X_train)-1)\n",
        "    x = X_train[index]\n",
        "    y = Y_train[index]\n",
        "\n",
        "    scores = model(x)\n",
        "    loss = criterion(scores, y) \n",
        "    losses.append(loss)\n",
        "\n",
        "  summed_loss = losses[0]\n",
        "  for loss in losses[1:]:\n",
        "    summed_loss = summed_loss + loss\n",
        "  summed_loss = summed_loss / batch_size\n",
        "  summed_loss.backward()\n",
        "  optimizer.step()\n",
        "  optimizer.zero_grad()\n",
        "  return summed_loss.detach().item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TU8Ni_lidncM"
      },
      "outputs": [],
      "source": [
        "#I create a class\n",
        "class RNN(nn.Module):\n",
        "  #define the constructor\n",
        "    def __init__(self, input_size, hidden_size, num_layers, num_classes, bidirectional=False, conv=False) -> None:\n",
        "        super(RNN,self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        #self.seq_length = seq_length\n",
        "\n",
        "        self.conv = conv\n",
        "        if self.conv:\n",
        "          self.nconv = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=(7,5),stride=(4,1),padding=\"valid\")\n",
        "        self.embed = nn.Linear(input_size, hidden_size+4)\n",
        "\n",
        "        self.lstm = nn.LSTM(hidden_size, hidden_size, num_layers, batch_first=False,bidirectional=bidirectional, dropout=0.05)\n",
        "        #This line creates a module for a linear transformation, ð‘¥ð–+ð‘xW+b\n",
        "        #fc means fully connected\n",
        "        if bidirectional:\n",
        "          self.fc = nn.Linear(hidden_size*2, num_classes) #(hidden_size*2, num_classes) if i wanted bidirection\n",
        "        else:\n",
        "          self.fc = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    #PyTorch networks created with nn.Module must have a forward method. It will take in a tensor and pass it\n",
        "    #through the operations that I have defined in the __init__ method \n",
        "    \n",
        "    def forward(self, x):\n",
        "        sequence_length, n_features = x.shape\n",
        "          #forward propagation of the input through LSTM\n",
        "        x = self.embed(x)\n",
        "        x = torch.relu(x)\n",
        "        if self.conv:\n",
        "          x = self.nconv(x.unsqueeze(0)).squeeze(0)\n",
        "        out, _ = self.lstm(x) #lstm with input, hidden, and internal state\n",
        "        # out = out.reshape(out.shape[0], -1) #reshaping the data for Dense Layer next\n",
        "        # Decode the hidden state of the last time step\n",
        "        out = self.fc(out[-1])\n",
        "        out = torch.sigmoid(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4krgE4oPUVN_"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "result_dir= Path('/content/drive/MyDrive/DeepLProject/models-conv2')\n",
        "result_dir.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "\n",
        "#here I initialize the model and check how the architecture is represented\n",
        "model = RNN(input_size=26,hidden_size=64, num_layers=1, num_classes=2, conv=True, bidirectional=False).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr = 0.001)\n",
        "n_epochs=7000\n",
        "best_model=0\n",
        "best_mod=0\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "  loss = train_step(model, optimizer, X_train, Y_train, batch_size=128)\n",
        "  if epoch % 50 == 0:\n",
        "    print(f\"Epoch {epoch}/{n_epochs} {loss=}\")\n",
        "    train_scores,(c0,c1) = evaluate(model, X_train, Y_train)\n",
        "    print(\"train\", train_scores)\n",
        "    score,(c0,c1) = evaluate(model, X_val, Y_val)\n",
        "    print(score, c0, c1)\n",
        "    if train_scores > best_mod:\n",
        "      best_mod=train_scores\n",
        "      torch.save(model.state_dict(), result_dir / f\"Train_model{score:.3f}_{c0}_{c1}\")\n",
        "    if score > best_model:\n",
        "      best_model=score\n",
        "      torch.save(model.state_dict(), result_dir / f\"Valid_model{score:.3f}_{c0}_{c1}\")\n",
        "\n",
        "\n",
        "print(f\"Epoch {epoch}/{n_epochs} {loss=}\")\n",
        "evaluate(model, X_val, Y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eNcT8iWBnceL",
        "outputId": "02f7aa04-b0bd-4993-ec31-4ad48fdce68f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/nn/modules/rnn.py:67: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.05 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[45.     45.8974 42.0513]\n",
            " [47.6923 52.9487 50.1282]\n",
            " [39.6154 43.7179 44.359 ]]\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "def infer(model_name: str, th0, th1, X, file: Path):\n",
        "  state_dict_file = Path('/content/drive/MyDrive/DeepLProject/models-conv2') / model_name\n",
        "  model = RNN(input_size=26,hidden_size=64, num_layers=1, num_classes=2, conv=True, bidirectional=False)\n",
        "  state_dict = torch.load(state_dict_file, map_location=device)\n",
        "  model.load_state_dict(state_dict)\n",
        "  model.to(device)\n",
        "  model.eval()\n",
        "\n",
        "  evaluate(model,X_val, Y_val)\n",
        "\n",
        "  with torch.no_grad():\n",
        "    predictions = []\n",
        "    for input in X:\n",
        "      scores = model(input)\n",
        "      prediction = torch.zeros(scores.shape, dtype=torch.int, device=device)\n",
        "      prediction[0][scores[0] >= th0] = 1\n",
        "      prediction[1][scores[1] >= th1] = 1\n",
        "      predictions.append(prediction) \n",
        "\n",
        "  #store in the format\n",
        "  results = {}\n",
        "  for count, values in enumerate(predictions):\n",
        "    results[f\"{count}\"]={\"valence\":values[0].item(), \"activation\":values[1].item()}\n",
        "\n",
        "  parent = file.parent\n",
        "  parent.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "  with open (file, \"w+\") as outfile:\n",
        "    json.dump(results, outfile)\n",
        "\n",
        "\n",
        "\n",
        "infer(\"model52.949_0.5_0.5\", 0.5,0.5, dev_X, Path('/content/drive/MyDrive/DeepLProject/submissions/test_final.json'))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iRDyBfZNEGzD",
        "outputId": "0f6ea710-935c-4093-e0b4-fecabbd8f964"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WEQGFYZ7Ecfq"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}